#!/bin/sh
#
# Array Express  package
#
# Author: sc
# TR: 12370
# Date: 08/24/2016
#

comment="gxdhtload"

# This will be used in the naming the log file
#
# set path of files on remote server
REMOTE_SITE=www.ebi.ac.uk

#url to remote site
REMOTE_SITE_URL=http://$REMOTE_SITE/
# v2 has the data we need for experiments, v3 is currently missing 'samples'
# AE says they need to fix v3
REMOTE_DIR=arrayexpress/json/v2

## List of files to download

# This gets ALL data  and works for v3 but v2 hangs
#REMOTE_FILES='experiments?organism=mus&exptype="RNA-seq of coding RNA"+OR+"RNA-seq of non coding RNA"+OR+"transcription profiling by array"+OR+"transcription profiling by tiling array"+OR+"microRNA profiling by array"+OR+"microRNA profiling by high-throughput sequencing"+OR+"tiling path by array"'

# this gets a date range 
SUBTRACT=1460 # four years
TODAY=`date`
DATE_TO_END=`date +%Y-%m-%d`
DATE_TO_BEGIN=`date -d "$TODAY - $SUBTRACT days" +%Y-%m-%d`
RANGE="[$DATE_TO_BEGIN $DATE_TO_END]"

# note we have to double quote the string to expand RANGE, so therefore must
# escape the double quotes around the attribute values (dbl quotes required)
# 2/17 added 
REMOTE_FILES="experiments?date=${RANGE}&organism=mus&exptype=\"RNA-seq of coding RNA\"+OR+\"RNA-seq of non coding RNA\"+OR+\"transcription profiling by array\"+OR+\"transcription profiling by tiling array\"+OR+\"microRNA profiling by array\"+OR+\"microRNA profiling by high-throughput sequencing\"+OR+\"RNA-seq of total RNA\"+OR+\"tiling path by array\""
LOCAL_DIR=$REMOTE_SITE
LOCAL_FILES="arrayexpress.json"

#
# The is_xml_query  variable is added for complex query strings to make sure 
# the REMOTE_FILES variable is parsed as a string by the download_mirror 
# script and not traited as an array - which is the default
is_xml_query=1

#
# wget options
# Log in as anonymous and give email as password
remote_user=anonymous
remote_password=mgscron@informatics.jax.org

WGET_OPTIONS="-O $LOCAL_FILES --user=$remote_user --password=$remote_password --no-parent -S -t 10 -nd -m"

#
# wget
# -S = print the headers sent by HTTP servers and responses sent by FTP servers.
# -o = full path to log file
# -O = full path to output file
# -t = number of retries
# -r = reverse
# -k 7 = sort by the 7th column
# -nd = don't create directories
# -m = Turn on options suitable for mirroring. This option turns on recursion 
#    and time-stamping, sets infinite recursion depth and keeps FTP 
#    directory listings. It is currently equivalent to .-r -N -l 
#    inf --no-remove-listing.. 
#-np
#  --no-parent
#    Do not ever ascend to the parent directory when retrieving recur-
#   sively.  This is a useful option, since it guarantees that only the
#   files below a certain hierarchy will be downloaded.

#******** Optional *************
# Do not download any files if local directories do not exist
local_dir_check=true

# Remove any files in local directory that are not in remote directory
do_deletes=false
recursive=false
